<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="generator" content="Hugo 0.57.2" />


<title>Scraping a News Website - Scott&#39;s Random Data Blogs</title>
<meta property="og:title" content="Scraping a News Website - Scott&#39;s Random Data Blogs">


  <link href='/home.png' rel='icon' type='image/x-icon'/>



  







<link rel="stylesheet" href="/css/fonts.css" media="all">
<link rel="stylesheet" href="/css/main.css" media="all">



  </head>
  <body>
    <div class="wrapper">
      <header class="header">
        <nav class="nav">
  <a href="/" class="nav-logo">
    <img src="/images/home.png"
         width="50"
         height="50"
         alt="Logo">
  </a>

  <ul class="nav-links">
    
    <li><a href="/about/">About</a></li>
    
    <li><a href="https://github.com/slee1088">GitHub</a></li>
    
  </ul>
</nav>

      </header>


<main class="content" role="main">

  <article class="article">
    
    <span class="article-duration">2 min read</span>
    

    <h1 class="article-title">Scraping a News Website</h1>

    
    <span class="article-date">2019-06-20</span>
    

    <div class="article-content">
      


<p><strong>Some Context</strong></p>
<p>One day after work, I was messaging with a friend (who’s extremely curious about data and it’s applications and a source of great ideas) and we were talking about scraping data from the internet and what tools were currently available and most easy to learn. R and Python sprang to mind and so we deep dived into some of the packages available in those languages. Then, funnily enough, the conversation turned to VBA and crude methods such as using sendkeys and how unreliable they were.</p>
<p>So, inspired as I usually am, I got home that night, turned my PC on and decided to scrap data from a couple of websites using R.</p>
<p><em>Please always be mindful of the legality of webscraping when you webscrape, useful link <a href="https://www.datahen.com/data-crawling-get-legal-side/?utm_source=Quora&amp;utm_medium=Answers">here</a>.</em></p>
<p><strong>My Workflow</strong></p>
<ul>
<li>I would say the package widely used in R for webscraping is <a href="https://blog.rstudio.com/2014/11/24/rvest-easy-web-scraping-with-r/">Rvest</a>. These are the packages I used in my workflow:
<ul>
<li><em>rvest</em></li>
<li><em>lubridate</em></li>
<li><em>dplyr</em></li>
<li><em>gmailr</em></li>
</ul></li>
<li>As the link to the Rvest blog points out, using <a href="https://selectorgadget.com/">selectorgadget</a> (a Chrome extension) makes finding the content you want to extract that much easier. It is possible without it but you would have to spend countless minutes trying to locate the css selector you are after.</li>
</ul>
<div class="figure">
<img src="/post/2019-08-31-first-post-basic-webscraping_files/webscrap1.png" alt="Click on the content you are after and the css selector will appear in the selectorgadget toolbar" />
<p class="caption"><em>Click on the content you are after and the css selector will appear in the selectorgadget toolbar</em></p>
</div>
<ul>
<li></li>
</ul>

    </div>
  </article>

  


</main>

      <footer class="footer">
        <ul class="footer-links">
          <li>
            <a href="/index.xml" type="application/rss+xml" target="_blank">RSS feed</a>
          </li>
          <li>
            <a href="https://gohugo.io/" class="footer-links-kudos">Made with <img src="/images/hugo-logo.png" alt="Img link to Hugo website" width="22" height="22"></a>
          </li>
        </ul>
      </footer>

    </div>
    

    

    
  </body>
</html>

